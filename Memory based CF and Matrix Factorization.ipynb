{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.1.2/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy import sparse\n",
    "import tqdm\n",
    "from math import sqrt\n",
    "from heapq import nlargest\n",
    "from tqdm import trange\n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('restaurants_places.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sample(frac = 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users:  30733\n",
      "Numebr of places:  31969\n"
     ]
    }
   ],
   "source": [
    "num_users = len(data['gPlusUserId'].unique())\n",
    "num_places = len(data['gPlusPlaceId'].unique())\n",
    "print(\"Number of users: \", num_users)\n",
    "print(\"Numebr of places: \", num_places)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmspe(y_true, y_pred):\n",
    "    \n",
    "    loss = np.sqrt(np.mean(np.square(((y_true - y_pred) / y_true)), axis=0))\n",
    "\n",
    "    return loss*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    \n",
    "    loss = np.sqrt(np.mean(np.square((y_true - y_pred)), axis=0))\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_users = LabelEncoder()\n",
    "le_users.fit(ratings['gPlusUserId'].unique())\n",
    "ratings['userId'] = le_users.transform(ratings['gPlusUserId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_items = LabelEncoder()\n",
    "le_items.fit(ratings['gPlusPlaceId'].unique())\n",
    "ratings['itemId'] = le_items.transform(ratings['gPlusPlaceId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df = ratings[['userId','itemId','rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8*len(ratings_df))\n",
    "ratings_df_train = ratings_df[:train_size]\n",
    "ratings_df_test = ratings_df[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train and test set for logistic text classifier\n",
    "train_df = ratings[:train_size]\n",
    "test_df = ratings[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataPreprocessor(rating_df, num_users, num_items):\n",
    "    \n",
    "    matrix = np.zeros((num_users,num_items)) #num_users x num_items\n",
    "\n",
    "    for (userID,itemID,rating) in rating_df.itertuples(index = False):\n",
    "      matrix[userID-1,itemID -1] = rating # -1 because minimum id number is 1\n",
    "    \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = dataPreprocessor(ratings_df_train, num_users, num_places)\n",
    "test_df = dataPreprocessor(ratings_df_test, num_users, num_places)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimBasedRecSys(object):\n",
    "\n",
    "    def __init__(self, base, method, processor=dataPreprocessor):\n",
    "        \n",
    "        self.base = base\n",
    "        self.method_name = method\n",
    "        self.method = self._getMethod(self.method_name)\n",
    "        self.processor = processor\n",
    "        self.pred_column_name = self.base+'-'+self.method_name\n",
    "    \n",
    "    def _getMethod(self, method_name):\n",
    "        \n",
    "        switcher = {\n",
    "            'cosine': self.cosine,\n",
    "            'euclidean': self.euclidean,\n",
    "            \n",
    "        }\n",
    "        \n",
    "        return switcher[method_name]\n",
    "    \n",
    "    @staticmethod\n",
    "    def cosine(matrix):\n",
    "        \n",
    "        similarity_matrix = 1 - pairwise_distances(matrix, metric='cosine')\n",
    "        return similarity_matrix\n",
    "    \n",
    "    @staticmethod\n",
    "    def euclidean(matrix):\n",
    "        \n",
    "        \n",
    "\n",
    "        similarity_matrix = 1/(1+pairwise_distances(matrix, metric='euclidean')) #lesser the distance more the similarity \n",
    "        \n",
    "        \n",
    "        return similarity_matrix\n",
    "    \n",
    "        \n",
    "    def predict_all(self, train_df, num_users, num_items):\n",
    "        \"\"\"\n",
    "            INPUT: \n",
    "                data: pandas DataFrame. columns=['userID', 'itemID', 'rating'...]\n",
    "                num_row: scalar. number of users\n",
    "                num_col: scalar. number of items\n",
    "            OUTPUT:\n",
    "                no return... this method assigns the result to self.model\n",
    "            \n",
    "            NOTES:\n",
    "                self.__model should contain predictions for *all* user and items\n",
    "                (don't worry about predicting for observed (user,item) pairs,\n",
    "                 since we won't be using these predictions in the evaluation)\n",
    "                (see code in for an efficient vectorized example)\n",
    "        \"\"\"\n",
    "        if self.processor is not None:\n",
    "          train_matrix = self.processor(train_df, num_users, num_items)\n",
    "        else:\n",
    "          train_matrix = train_df #if processer is none\n",
    "        if self.base == 'user':\n",
    "            \n",
    "            temp_matrix = np.zeros(train_matrix.shape)\n",
    "            temp_matrix[train_matrix.nonzero()] = 1 #assign 1 to the items that have been rated\n",
    "\n",
    "            uu_similarity = 1 - pairwise_distances(train_matrix, metric='cosine') #similarity matrix\n",
    "            \n",
    "            # UxI: UxU mul UxI\n",
    "            normalizer = np.matmul(uu_similarity, temp_matrix) \n",
    "            #print(normalizer)\n",
    "            normalizer[normalizer == 0] = 1e-5 #to avoid dividing by zero\n",
    "            \n",
    "            \n",
    "            predictionMatrix = np.matmul(uu_similarity, train_matrix)/normalizer #U*I\n",
    "            #predictionMatrix[temp_matrix.nonzero()] = 0\n",
    "            #Cold start\n",
    "            # if no one has rated this item before, use user average  \n",
    "            useraverage = np.sum(train_matrix, axis=1)/(np.sum(temp_matrix, axis=1)+1e-5)\n",
    "            columns = np.sum(predictionMatrix, axis=0)  \n",
    "            print(columns.shape)\n",
    "            predictionMatrix[:, columns==0] = predictionMatrix[:, columns==0] + np.expand_dims(useraverage, axis=1)\n",
    "\n",
    "            #output\n",
    "            self.__model = predictionMatrix\n",
    "\n",
    "            \n",
    "            \n",
    "        elif self.base == 'item':\n",
    "            \n",
    "            train_matrix_1 = train_matrix.transpose() #IxU\n",
    "            temp_matrix = np.zeros(train_matrix_1.shape)\n",
    "            temp_matrix[train_matrix_1.nonzero()] = 1 #assign 1 to the items that have been rated\n",
    "\n",
    "            ii_similarity = 1 - pairwise_distances(train_matrix_1, metric='cosine') #similarity matrix\n",
    "            \n",
    "            # IxI x IxU: IxU\n",
    "            normalizer = np.matmul(ii_similarity, temp_matrix) \n",
    "            #print(normalizer)\n",
    "            normalizer[normalizer == 0] = 1e-5 #to avoid dividing by zero\n",
    "            \n",
    "            \n",
    "            predictionMatrix = np.matmul(ii_similarity, train_matrix_1)/normalizer #IxU\n",
    "            #predictionMatrix[temp_matrix.nonzero()] = 0\n",
    "            #Cold start\n",
    "            # if no one has rated this item before, use user average  \n",
    "            itemaverage = np.sum(train_matrix_1, axis=1)/(np.sum(temp_matrix, axis=1) +1e-5)\n",
    "            columns = np.sum(predictionMatrix, axis=0) #find the \n",
    "            #print(columns.shape)\n",
    "            predictionMatrix[:, columns==0] = predictionMatrix[:, columns==0] + np.expand_dims(itemaverage, axis=1)\n",
    "\n",
    "            #output\n",
    "            self.__model = predictionMatrix.transpose() #UxI\n",
    "            \n",
    "        else:\n",
    "            print('No other option available')\n",
    "        \n",
    "    def evaluate_test(self, test_df, copy=False):\n",
    "        \n",
    "        if copy:\n",
    "            prediction = test_df.copy()\n",
    "        else:\n",
    "            prediction = test_df\n",
    "        prediction[self.pred_column_name] = np.nan\n",
    "        \n",
    "        \n",
    "        for (index, \n",
    "             userID, \n",
    "             itemID) in prediction[['userID','itemID']].itertuples():\n",
    "            prediction.loc[index, self.pred_column_name] = self.__model[userID-1, itemID-1]\n",
    "    \n",
    "        return prediction\n",
    "    \n",
    "    def getModel(self):\n",
    "        \n",
    "        #returns predicted user-item matrix\n",
    "        \n",
    "        return self.__model\n",
    "    \n",
    "    def getPredColName(self):\n",
    "        \n",
    "        # returns prediction column name\n",
    "        \n",
    "        return self.pred_column_name\n",
    "    \n",
    "    def reset(self):\n",
    "        \n",
    "        #reuse the instance of the class by removing model\n",
    "        \n",
    "        try:\n",
    "            self.model = None\n",
    "        except:\n",
    "            print(\"You do not have model..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_cosine_recsys = SimBasedRecSys('user','cosine', processor = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31969,)\n"
     ]
    }
   ],
   "source": [
    "user_cosine_recsys.predict_all(train_df, num_users, num_places)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df_train.columns = ['userID', 'itemID', 'rating']\n",
    "ratings_df_test.columns = ['userID', 'itemID', 'rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_ratings_train = user_cosine_recsys.evaluate_test(ratings_df_train,copy=True)\n",
    "cf_ratings_test = user_cosine_recsys.evaluate_test(ratings_df_test, copy = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evalaution of user-user CF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Based Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('vectorizer', CountVectorizer(max_features = 5000)),\n",
    "('tfidf',TfidfTransformer()),\n",
    "('model',LogisticRegression(max_iter = 300))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for text based model we consider review text as the feature space and target variable as rating\n",
    "x_train = train_df['reviewText']\n",
    "y_train = train_df['rating']\n",
    "x_test = test_df['reviewText']\n",
    "y_test = test_df['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer', CountVectorizer(max_features=5000)),\n",
       "                ('tfidf', TfidfTransformer()),\n",
       "                ('model', LogisticRegression(max_iter=300))])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = pipe.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_predictions = pipe.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5621539463684725\n"
     ]
    }
   ],
   "source": [
    "score = pipe.score(x_test,y_test)\n",
    "print(\"Accuracy: \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5621539463684725"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,text_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53.61817719131021"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmspe_text = rmspe(y_test,text_predictions)\n",
    "rmspe_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9014222125719249"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test,text_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  0.4578991185171457\n"
     ]
    }
   ],
   "source": [
    "print(\"RMSE: \",rmse(cf_ratings_train['rating'], cf_ratings_train['user-cosine']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combination of Memory Based Collaborative Filter and Text Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for both models combined:  1.8712465555905038\n"
     ]
    }
   ],
   "source": [
    "test_pred = (text_predictions + cf_ratings_test['user-cosine'])/2\n",
    "print(\"RMSE for both models combined: \", rmse(y_test, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for both models combined:  0.5100508734605291\n"
     ]
    }
   ],
   "source": [
    "train_pred = (train_predictions + cf_ratings_train['user-cosine'])/2\n",
    "print(\"RMSE for both models combined: \", rmse(y_train, train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PMFRecSys(object):\n",
    "    def __init__(self, num_feat=10, epsilon=1, _lambda=0.1, momentum=0.8, maxepoch=20, num_batches=10, batch_size=1000):\n",
    "        \"\"\"\n",
    "            num_feat: int, number of latent features\n",
    "            epsilon: float, learning rate\n",
    "            _lambda: float, L2 regularization,\n",
    "            momentum: float, momentum of the gradient,\n",
    "            maxepoch: float, Number of epoch before stop,\n",
    "            num_batches: int, Number of batches in each epoch (for SGD optimization),\n",
    "            batch_size:Number int, of training samples used in each batches (for SGD optimization)\n",
    "            \n",
    "        \"\"\"\n",
    "        self.num_feat = num_feat  # Number of latent features,\n",
    "        self.epsilon = epsilon  # learning rate,\n",
    "        self._lambda = _lambda  # L2 regularization,\n",
    "        self.momentum = momentum  # momentum of the gradient,\n",
    "        self.maxepoch = maxepoch  # Number of epoch before stop,\n",
    "        self.num_batches = num_batches  # Number of batches in each epoch (for SGD optimization),\n",
    "        self.batch_size = batch_size  # Number of training samples used in each batches (for SGD optimization)\n",
    "        self.test = False\n",
    "        self.w_Item = None  # Item feature vectors\n",
    "        self.w_User = None  # User feature vectors\n",
    "        \n",
    "        self.rmse_train = []\n",
    "        self.rmse_test = []\n",
    "        self.pred_column_name='PMF'\n",
    "\n",
    "    def predict_all(self, train_vec, num_user, num_item):\n",
    "        \"\"\"\n",
    "            INPUT: \n",
    "                data: pandas DataFrame. columns=['userID', 'itemID', 'rating'...]\n",
    "                num_user: scalar. number of users\n",
    "                num_item: scalar. number of items\n",
    "            OUTPUT:\n",
    "                no return... this method update w_User and w_Item\n",
    "            \n",
    "            NOTES:\n",
    "                self.W_Item and self.W_User are use to do the final predition for a user\n",
    "                \n",
    "        \"\"\"\n",
    "        # select 'userID', 'itemID', 'rating only\n",
    "        train_vec = train_vec.iloc[:, :3].values  \n",
    "        if self.test:\n",
    "          train_vec, val_vec = train_test_split(train_vec)\n",
    "          pairs_val = val_vec.shape[0] #number of rating in validation set\n",
    "          self.mean_rating_test = np.mean(val_vec[:, 2])\n",
    "        self.mean_rating_train = np.mean(train_vec[:, 2])  # avg rating (assign average rating to mean_rating_train)\n",
    "        pairs_train = train_vec.shape[0]  # num of rating in training set \n",
    "        \n",
    "\n",
    "        # to avoid out of bound\n",
    "        num_user += 1  \n",
    "        num_item += 1  \n",
    "        # initialize\n",
    "        self.epoch = 0\n",
    "        \n",
    "        \n",
    "    \n",
    "        self.w_Item = 0.1*np.random.randn(num_item,self.num_feat)  # item M x D  \n",
    "        self.w_User = 0.1*np.random.randn(num_user,self.num_feat)   # user N x D \n",
    "    \n",
    "    \n",
    "         \n",
    "\n",
    "        self.w_Item_inc = np.zeros((num_item, self.num_feat))  # accumulate the gradient\n",
    "        self.w_User_inc = np.zeros((num_user, self.num_feat))  # accumulate the gradient\n",
    "        while self.epoch < self.maxepoch: \n",
    "            self.epoch += 1\n",
    "\n",
    "            # Shuffle training truples\n",
    "            shuffled_order = np.arange(train_vec.shape[0])  #number of ratings\n",
    "            np.random.shuffle(shuffled_order)  #shuffled  \n",
    "\n",
    "            # Batch update\n",
    "            for batch in range(self.num_batches): \n",
    "                \n",
    "\n",
    "                test = np.arange(self.batch_size * batch, self.batch_size * (batch + 1)) #batch 1: (1000,2000) \n",
    "                batch_idx = np.mod(test, shuffled_order.shape[0])  # get the real data index #(batch_size,)\n",
    "\n",
    "\n",
    "                batch_UserID = np.array(train_vec[shuffled_order[batch_idx], 0], dtype='int32') #(batch_size,)\n",
    "                batch_ItemID = np.array(train_vec[shuffled_order[batch_idx], 1], dtype='int32') #(batch_size,)\n",
    "\n",
    "                \n",
    "                \n",
    "                pred_out = np.sum(np.multiply(self.w_User[batch_UserID],self.w_Item[batch_ItemID]),axis = 1) #size (batch_size, )\n",
    "                #print(pred_out)\n",
    "                #print(pred_out.shape)\n",
    "                #input(\"stop\")\n",
    "\n",
    "                rawErr = pred_out + self.mean_rating_train - train_vec[shuffled_order[batch_idx], 2]\n",
    "\n",
    "                # Compute gradients\n",
    "                Ix_User = 2 * np.multiply(rawErr[:, np.newaxis], self.w_Item[batch_ItemID, :]) \\\n",
    "                       + self._lambda * self.w_User[batch_UserID, :]\n",
    "                Ix_Item = 2 * np.multiply(rawErr[:, np.newaxis], self.w_User[batch_UserID, :]) \\\n",
    "                       + self._lambda * (self.w_Item[batch_ItemID, :])  # np.newaxis :increase the dimension\n",
    "\n",
    "                dw_Item = np.zeros((num_item, self.num_feat))\n",
    "                dw_User = np.zeros((num_user, self.num_feat))\n",
    "\n",
    "                # loop to aggreate the gradients of the same element\n",
    "                for i in range(self.batch_size):\n",
    "                    dw_Item[batch_ItemID[i], :] += Ix_Item[i, :]\n",
    "                    dw_User[batch_UserID[i], :] += Ix_User[i, :]\n",
    "\n",
    "                # Update with momentum\n",
    "                self.w_Item_inc = self.momentum * self.w_Item_inc + self.epsilon * dw_Item / self.batch_size\n",
    "                self.w_User_inc = self.momentum * self.w_User_inc + self.epsilon * dw_User / self.batch_size\n",
    "\n",
    "                self.w_Item = self.w_Item - self.w_Item_inc \n",
    "                self.w_User = self.w_User - self.w_User_inc\n",
    "\n",
    "                # Compute Compute mean rating subtracted rating \n",
    "                if batch == self.num_batches - 1:\n",
    "                    train_user_idx = np.array(train_vec[:, 0], dtype='int32')\n",
    "                    train_item_idx = np.array(train_vec[:, 1], dtype='int32')\n",
    "                    \n",
    "            \n",
    "                    pred_out = np.sum(np.multiply(self.w_User[train_user_idx],self.w_Item[train_item_idx]),axis = 1)  # size(pairs_train, )\n",
    "                    #print(pred_out)\n",
    "                    #print(pairs_train)\n",
    "                    #print(pred_out.shape)\n",
    "                    \n",
    "                    rawErr = pred_out + self.mean_rating_train - train_vec[:, 2] \n",
    "                    obj = np.linalg.norm(rawErr) ** 2 \\\n",
    "                          + 0.5 * self._lambda * (np.linalg.norm(self.w_User) ** 2 + np.linalg.norm(self.w_Item) ** 2)\n",
    "\n",
    "                    self.rmse_train.append(np.sqrt(obj / pairs_train))\n",
    "\n",
    "                # Compute validation error\n",
    "                if batch == self.num_batches - 1 and self.test:\n",
    "                    val_user_idx = np.array(val_vec[:, 0], dtype='int32')\n",
    "                    val_item_idx = np.array(val_vec[:, 1], dtype='int32')\n",
    "                    \n",
    "            \n",
    "                    pred_out = np.sum(np.multiply(self.w_User[val_user_idx],self.w_Item[val_item_idx]),axis = 1) #size(pairs_val, )\n",
    "                    \n",
    "                    rawErr = pred_out + self.mean_rating_test - val_vec[:, 2]\n",
    "                    self.rmse_test.append(np.linalg.norm(rawErr) / np.sqrt(pairs_val))\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "    def evaluate_test(self, test_df, copy=False):\n",
    "        \"\"\"\n",
    "            INPUT:\n",
    "                data: pandas DataFrame. columns=['userID', 'itemID', 'rating'...]\n",
    "            OUTPUT:\n",
    "                predictions:  pandas DataFrame. \n",
    "                              columns=['userID', 'itemID', 'rating', 'base-method'...]\n",
    "                              \n",
    "        \"\"\"\n",
    "        if copy:\n",
    "            prediction = pd.DataFrame(test_df.copy(), columns=['userID', 'itemID', 'rating'])\n",
    "        else:\n",
    "            prediction = pd.DataFrame(test_df, columns=['userID', 'itemID', 'rating'])\n",
    "        prediction[self.pred_column_name] = np.nan\n",
    "        \n",
    "        for (index, \n",
    "             userID, \n",
    "             itemID) in tqdm(prediction[['userID','itemID']].itertuples()):\n",
    "            prediction.loc[index, self.pred_column_name] = (np.dot(self.w_Item, self.w_User[int(userID), :]) + self.mean_rating_train)[int(itemID)]\n",
    "    \n",
    "        return prediction\n",
    "    \n",
    "    def plot_error(self):\n",
    "      if self.test:\n",
    "        plt.plot(range(pmf.maxepoch), pmf.rmse_test, marker='v', label='Test Data')\n",
    "      plt.plot(range(pmf.maxepoch), pmf.rmse_train, marker='o', label='Training Data')\n",
    "      plt.title('Learning Curve')\n",
    "      plt.xlabel('Number of Epochs')\n",
    "      plt.ylabel('RMSE')\n",
    "      plt.legend()\n",
    "      plt.grid()\n",
    "      plt.show()\n",
    "          \n",
    "    def getPredColName(self):\n",
    "        \"\"\"\n",
    "            return prediction column name\n",
    "        \"\"\"\n",
    "        return self.pred_column_name\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "            reuse the instance of the class by removing model\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.w_Item = None \n",
    "            self.w_User = None \n",
    "        except:\n",
    "            print(\"You do not have w_Item, w_User\")\n",
    "\n",
    "    def set_params(self, parameters):\n",
    "        if isinstance(parameters, dict):\n",
    "            self.num_feat = parameters.get(\"num_feat\", 10)\n",
    "            self.epsilon = parameters.get(\"epsilon\", 1)\n",
    "            self._lambda = parameters.get(\"_lambda\", 0.1)\n",
    "            self.momentum = parameters.get(\"momentum\", 0.8)\n",
    "            self.maxepoch = parameters.get(\"maxepoch\", 20)\n",
    "            self.num_batches = parameters.get(\"num_batches\", 10)\n",
    "            self.batch_size = parameters.get(\"batch_size\", 1000)\n",
    "            self.test = parameters.get(\"test_mode\", False)\n",
    "        else:\n",
    "          raise Exception(\"You need to pass in a dictionary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmf = PMFRecSys()\n",
    "pmf.set_params({\"num_feat\": 20, \"epsilon\": 0.4, \"_lambda\": 0.01, \"momentum\": 0.8, \"maxepoch\": 100, \"num_batches\": 100,\n",
    "                \"batch_size\": 1000, 'test_mode':True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmf.predict_all(ratings_df_train, num_users, num_places)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pmf.plot_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "36841it [31:36, 19.43it/s] \n",
      "9211it [00:26, 348.88it/s]\n"
     ]
    }
   ],
   "source": [
    "cf_ratings_train_pmf = pmf.evaluate_test(ratings_df_train,copy = True)\n",
    "cf_ratings_test_pmf = pmf.evaluate_test(ratings_df_test, copy = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['userID', 'itemID', 'rating', 'PMF'], dtype='object')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf_ratings_test_pmf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  0.6527843070452839\n"
     ]
    }
   ],
   "source": [
    "print(\"RMSE: \", rmse(cf_ratings_train_pmf['rating'], cf_ratings_train_pmf['PMF']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
