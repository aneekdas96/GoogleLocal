{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Concatenate, Dense, Input, LSTM, Embedding, Dropout, Activation, GRU, Flatten\n",
    "from tensorflow.keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Convolution1D\n",
    "from tensorflow.keras import initializers, regularizers, constraints, optimizers, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df = pd.read_pickle('food_review_places.pickle') #275568 observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70195"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(review_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df = review_df[review_df['rating']!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0    34487\n",
       "4.0    19041\n",
       "3.0     8118\n",
       "2.0     5010\n",
       "1.0     3539\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df['rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder()\n",
    "reviews = list(review_df['reviewText'])\n",
    "ratings = np.array(list(review_df['rating']))\n",
    "# one-hot encode the ratings\n",
    "ratings = enc.fit_transform(ratings.reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 0.8\n",
    "train_len = int(split * len(reviews))\n",
    "train_reviews = np.array(reviews[:train_len])\n",
    "train_ratings = np.array(ratings[:train_len])\n",
    "test_reviews = np.array(reviews[train_len:])\n",
    "test_ratings = np.array(ratings[train_len:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\py36gpu\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\preprocessing\\text_vectorization.py:338: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return np.array(preprocessed_data.to_list())\n"
     ]
    }
   ],
   "source": [
    "max_size = 1000\n",
    "vectorize_layer = tf.keras.layers.experimental.preprocessing.TextVectorization(max_tokens=max_size, output_mode='int', output_sequence_length=14)\n",
    "vectorize_layer.adapt(train_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input(shape=(1, ), dtype=tf.string, name='text')\n",
    "outputs = vectorize_layer(inputs)\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "# vocab = np.array(vectorize_layer.get_vocabulary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_train_reviews = model.predict(train_reviews)\n",
    "encoded_test_reviews = model.predict(test_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attention "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(tf.keras.Model):\n",
    "    def __init__(self, units):\n",
    "        super(Attention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    " \n",
    "    def call(self, features, hidden):\n",
    "        # hidden shape == (batch_size, hidden size)\n",
    "        # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "        # we are doing this to perform addition to calculate the score\n",
    "        hidden_with_time_axis = tf.expand_dims(hidden, 1)\n",
    "\n",
    "        # score shape == (batch_size, max_length, 1)\n",
    "        # we get 1 at the last axis because we are applying score to self.V\n",
    "        # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
    "        score = tf.nn.tanh(\n",
    "            self.W1(features) + self.W2(hidden_with_time_axis))\n",
    "        \n",
    "        # attention_weights shape == (batch_size, max_length, 1)\n",
    "        attention_weights = tf.nn.softmax(self.V(score), axis=1)\n",
    "\n",
    "        # context_vector shape after sum == (batch_size, hidden_size)\n",
    "        context_vector = attention_weights * features\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    " \n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = Input(shape=(14,), dtype=\"int32\")\n",
    "layer1 = Embedding(input_dim=1001, output_dim=128, mask_zero=True)(input_layer)\n",
    "lstm = Bidirectional(LSTM(10, return_sequences = True), name=\"bi_lstm_0\")(layer1)\n",
    "(lstm, forward_h, forward_c, backward_h, backward_c) = Bidirectional(LSTM(128, return_sequences=True, return_state=True), name=\"bi_lstm_1\")(lstm)\n",
    "state_h = Concatenate()([forward_h, backward_h])\n",
    "state_c = Concatenate()([forward_c, backward_c])\n",
    "\n",
    "context_vector, attention_weights = Attention(10)(lstm, state_h)\n",
    "\n",
    "dense1 = Dense(128, activation='relu')(context_vector)\n",
    "dense2 = Dense(32, activation='relu')(dense1)\n",
    "\n",
    "dropout = Dropout(0.1)(dense2)\n",
    "output = Dense(5, activation='softmax')(dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    " model = tf.keras.Model(input_layer, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_19\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_12 (InputLayer)           [(None, 14)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_18 (Embedding)        (None, 14, 128)      128128      input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bi_lstm_0 (Bidirectional)       (None, 14, 20)       11120       embedding_18[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bi_lstm_1 (Bidirectional)       [(None, 14, 256), (N 152576      bi_lstm_0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_32 (Concatenate)    (None, 256)          0           bi_lstm_1[0][1]                  \n",
      "                                                                 bi_lstm_1[0][3]                  \n",
      "__________________________________________________________________________________________________\n",
      "attention_16 (Attention)        ((None, 256), (None, 5151        bi_lstm_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_84 (Dense)                (None, 128)          32896       attention_16[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_85 (Dense)                (None, 32)           4128        dense_84[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 32)           0           dense_85[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_86 (Dense)                (None, 5)            165         dropout_15[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 334,164\n",
      "Trainable params: 334,164\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1404/1404 [==============================] - 98s 69ms/step - loss: 1.0297 - accuracy: 0.5483 - val_loss: 0.9848 - val_accuracy: 0.5670\n",
      "Epoch 2/10\n",
      "1404/1404 [==============================] - 97s 69ms/step - loss: 0.9477 - accuracy: 0.5826 - val_loss: 0.9696 - val_accuracy: 0.5744\n",
      "Epoch 3/10\n",
      "1404/1404 [==============================] - 95s 68ms/step - loss: 0.9288 - accuracy: 0.5918 - val_loss: 0.9776 - val_accuracy: 0.5723\n",
      "Epoch 4/10\n",
      "1404/1404 [==============================] - 97s 69ms/step - loss: 0.9120 - accuracy: 0.5975 - val_loss: 0.9764 - val_accuracy: 0.5731\n",
      "Epoch 5/10\n",
      "1404/1404 [==============================] - 99s 70ms/step - loss: 0.8989 - accuracy: 0.6040 - val_loss: 0.9836 - val_accuracy: 0.5668\n",
      "Epoch 6/10\n",
      "1404/1404 [==============================] - 96s 68ms/step - loss: 0.8826 - accuracy: 0.6110 - val_loss: 0.9954 - val_accuracy: 0.5710\n",
      "Epoch 7/10\n",
      "1404/1404 [==============================] - 95s 68ms/step - loss: 0.8656 - accuracy: 0.6166 - val_loss: 1.0054 - val_accuracy: 0.5647\n",
      "Epoch 8/10\n",
      "1404/1404 [==============================] - 96s 68ms/step - loss: 0.8484 - accuracy: 0.6236 - val_loss: 1.0182 - val_accuracy: 0.5678\n",
      "Epoch 9/10\n",
      "1404/1404 [==============================] - 94s 67ms/step - loss: 0.8332 - accuracy: 0.6305 - val_loss: 1.0539 - val_accuracy: 0.5603\n",
      "Epoch 10/10\n",
      "1404/1404 [==============================] - 95s 68ms/step - loss: 0.8153 - accuracy: 0.6376 - val_loss: 1.0528 - val_accuracy: 0.5642\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(encoded_train_reviews, train_ratings, batch_size=32, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1723/1723 [==============================] - 5s 3ms/step - loss: 0.9652 - accuracy: 0.5706\n"
     ]
    }
   ],
   "source": [
    "score, acc = model.evaluate(encoded_test_reviews, test_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
