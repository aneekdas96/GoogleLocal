{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf \n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Concatenate, Dense, Input, LSTM, Embedding, Dropout, Activation, GRU, Flatten\n",
    "from tensorflow.keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Convolution1D\n",
    "from tensorflow.keras import initializers, regularizers, constraints, optimizers, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df = pd.read_pickle('food_review_places.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0    34487\n",
       "4.0    19041\n",
       "3.0     8118\n",
       "2.0     5010\n",
       "1.0     3539\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df['rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gPlusPlaceId</th>\n",
       "      <th>rating</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>categories</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>gPlusUserId</th>\n",
       "      <th>name</th>\n",
       "      <th>price</th>\n",
       "      <th>...</th>\n",
       "      <th>hours</th>\n",
       "      <th>phone</th>\n",
       "      <th>closed</th>\n",
       "      <th>gps</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>open_days</th>\n",
       "      <th>Dinner</th>\n",
       "      <th>Lunch</th>\n",
       "      <th>Breakfast</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>112181651134020562716</td>\n",
       "      <td>5.0</td>\n",
       "      <td>jason wagner</td>\n",
       "      <td>stop dinner mahi mahi special fantast servic g...</td>\n",
       "      <td>[european restaurant, italian restaurant]</td>\n",
       "      <td>2012-10-18 21:56:05</td>\n",
       "      <td>2012-10-18</td>\n",
       "      <td>100000196778399872657</td>\n",
       "      <td>Pasquales Trattoria</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>[[Monday, [['Closed']]], [Tuesday, [['11:30 am...</td>\n",
       "      <td>(905) 338-9090</td>\n",
       "      <td>False</td>\n",
       "      <td>[43.440331, -79.672851]</td>\n",
       "      <td>43.440331</td>\n",
       "      <td>-79.672851</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>109391653021436219474</td>\n",
       "      <td>5.0</td>\n",
       "      <td>heather goldsworthy</td>\n",
       "      <td>best coffe collingwood</td>\n",
       "      <td>[cafe]</td>\n",
       "      <td>2013-09-12 18:38:15</td>\n",
       "      <td>2013-09-12</td>\n",
       "      <td>100000427343266187570</td>\n",
       "      <td>Espresso Post</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>(705) 446-1740</td>\n",
       "      <td>False</td>\n",
       "      <td>[44.499252, -80.216587]</td>\n",
       "      <td>44.499252</td>\n",
       "      <td>-80.216587</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>109391653021436219474</td>\n",
       "      <td>5.0</td>\n",
       "      <td>nicholas clayton</td>\n",
       "      <td>locat old post offic outlet histor pedigre bes...</td>\n",
       "      <td>[cafe]</td>\n",
       "      <td>2013-05-04 01:35:12</td>\n",
       "      <td>2013-05-03</td>\n",
       "      <td>104975196938413074237</td>\n",
       "      <td>Espresso Post</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>(705) 446-1740</td>\n",
       "      <td>False</td>\n",
       "      <td>[44.499252, -80.216587]</td>\n",
       "      <td>44.499252</td>\n",
       "      <td>-80.216587</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>110864889964667973890</td>\n",
       "      <td>5.0</td>\n",
       "      <td>chris johnson</td>\n",
       "      <td>get right everi time love guy</td>\n",
       "      <td>[delivery restaurant, event planner, business ...</td>\n",
       "      <td>2011-09-15 21:54:03</td>\n",
       "      <td>2011-09-15</td>\n",
       "      <td>100000524810171549476</td>\n",
       "      <td>Delivered Dish | Portland, OR</td>\n",
       "      <td>$$</td>\n",
       "      <td>...</td>\n",
       "      <td>[[Monday, [['8:00 am--9:00 pm']]], [Tuesday, [...</td>\n",
       "      <td>(503) 239-0100</td>\n",
       "      <td>False</td>\n",
       "      <td>[45.470342, -122.747085]</td>\n",
       "      <td>45.470342</td>\n",
       "      <td>-122.747085</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>110864889964667973890</td>\n",
       "      <td>1.0</td>\n",
       "      <td>allison lea</td>\n",
       "      <td>use servic order even show 1 hour 20 minut pro...</td>\n",
       "      <td>[delivery restaurant, event planner, business ...</td>\n",
       "      <td>2013-11-09 10:28:01</td>\n",
       "      <td>2013-11-08</td>\n",
       "      <td>100537426867747151661</td>\n",
       "      <td>Delivered Dish | Portland, OR</td>\n",
       "      <td>$$</td>\n",
       "      <td>...</td>\n",
       "      <td>[[Monday, [['8:00 am--9:00 pm']]], [Tuesday, [...</td>\n",
       "      <td>(503) 239-0100</td>\n",
       "      <td>False</td>\n",
       "      <td>[45.470342, -122.747085]</td>\n",
       "      <td>45.470342</td>\n",
       "      <td>-122.747085</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            gPlusPlaceId  rating         reviewerName  \\\n",
       "0  112181651134020562716     5.0         jason wagner   \n",
       "1  109391653021436219474     5.0  heather goldsworthy   \n",
       "2  109391653021436219474     5.0     nicholas clayton   \n",
       "3  110864889964667973890     5.0        chris johnson   \n",
       "4  110864889964667973890     1.0          allison lea   \n",
       "\n",
       "                                          reviewText  \\\n",
       "0  stop dinner mahi mahi special fantast servic g...   \n",
       "1                             best coffe collingwood   \n",
       "2  locat old post offic outlet histor pedigre bes...   \n",
       "3                      get right everi time love guy   \n",
       "4  use servic order even show 1 hour 20 minut pro...   \n",
       "\n",
       "                                          categories      unixReviewTime  \\\n",
       "0          [european restaurant, italian restaurant] 2012-10-18 21:56:05   \n",
       "1                                             [cafe] 2013-09-12 18:38:15   \n",
       "2                                             [cafe] 2013-05-04 01:35:12   \n",
       "3  [delivery restaurant, event planner, business ... 2011-09-15 21:54:03   \n",
       "4  [delivery restaurant, event planner, business ... 2013-11-09 10:28:01   \n",
       "\n",
       "  reviewTime            gPlusUserId                           name price  ...  \\\n",
       "0 2012-10-18  100000196778399872657            Pasquales Trattoria  None  ...   \n",
       "1 2013-09-12  100000427343266187570                  Espresso Post  None  ...   \n",
       "2 2013-05-03  104975196938413074237                  Espresso Post  None  ...   \n",
       "3 2011-09-15  100000524810171549476  Delivered Dish | Portland, OR    $$  ...   \n",
       "4 2013-11-08  100537426867747151661  Delivered Dish | Portland, OR    $$  ...   \n",
       "\n",
       "                                               hours           phone closed  \\\n",
       "0  [[Monday, [['Closed']]], [Tuesday, [['11:30 am...  (905) 338-9090  False   \n",
       "1                                               None  (705) 446-1740  False   \n",
       "2                                               None  (705) 446-1740  False   \n",
       "3  [[Monday, [['8:00 am--9:00 pm']]], [Tuesday, [...  (503) 239-0100  False   \n",
       "4  [[Monday, [['8:00 am--9:00 pm']]], [Tuesday, [...  (503) 239-0100  False   \n",
       "\n",
       "                        gps        lat        long  open_days  Dinner  Lunch  \\\n",
       "0   [43.440331, -79.672851]  43.440331  -79.672851        6.0     1.0    0.0   \n",
       "1   [44.499252, -80.216587]  44.499252  -80.216587        NaN     NaN    NaN   \n",
       "2   [44.499252, -80.216587]  44.499252  -80.216587        NaN     NaN    NaN   \n",
       "3  [45.470342, -122.747085]  45.470342 -122.747085        7.0     1.0    0.0   \n",
       "4  [45.470342, -122.747085]  45.470342 -122.747085        7.0     1.0    0.0   \n",
       "\n",
       "   Breakfast  \n",
       "0        0.0  \n",
       "1        NaN  \n",
       "2        NaN  \n",
       "3        0.0  \n",
       "4        0.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder()\n",
    "reviews = list(review_df['reviewText'])\n",
    "ratings = np.array(list(review_df['rating']))\n",
    "# one-hot encode the ratings\n",
    "ratings = enc.fit_transform(ratings.reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 0.8\n",
    "train_len = int(split * len(reviews))\n",
    "train_reviews = np.array(reviews[:train_len])\n",
    "train_ratings = np.array(ratings[:train_len])\n",
    "test_reviews = np.array(reviews[train_len:])\n",
    "test_ratings = np.array(ratings[train_len:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\py36gpu\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\preprocessing\\text_vectorization.py:338: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return np.array(preprocessed_data.to_list())\n"
     ]
    }
   ],
   "source": [
    "max_size = 1000\n",
    "vectorize_layer = tf.keras.layers.experimental.preprocessing.TextVectorization(max_tokens=max_size, output_mode='int', output_sequence_length=20)\n",
    "vectorize_layer.adapt(train_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input(shape=(1, ), dtype=tf.string, name='text')\n",
    "outputs = vectorize_layer(inputs)\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "# vocab = np.array(vectorize_layer.get_vocabulary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_train_reviews = model.predict(train_reviews)\n",
    "encoded_test_reviews = model.predict(test_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi-head attention Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class MultiHeadSelfAttention(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads=8):\n",
    "        super(MultiHeadSelfAttention, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        if embed_dim % num_heads != 0:\n",
    "            raise ValueError(\n",
    "                f\"embedding dimension = {embed_dim} should be divisible by number of heads = {num_heads}\"\n",
    "            )\n",
    "        self.projection_dim = embed_dim // num_heads\n",
    "        self.query_dense = layers.Dense(embed_dim)\n",
    "        self.key_dense = layers.Dense(embed_dim)\n",
    "        self.value_dense = layers.Dense(embed_dim)\n",
    "        self.combine_heads = layers.Dense(embed_dim)\n",
    "\n",
    "    def attention(self, query, key, value):\n",
    "        score = tf.matmul(query, key, transpose_b=True)\n",
    "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "        scaled_score = score / tf.math.sqrt(dim_key)\n",
    "        weights = tf.nn.softmax(scaled_score, axis=-1)\n",
    "        output = tf.matmul(weights, value)\n",
    "        return output, weights\n",
    "\n",
    "    def separate_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # x.shape = [batch_size, seq_len, embedding_dim]\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        query = self.query_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
    "        key = self.key_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
    "        value = self.value_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
    "        query = self.separate_heads(\n",
    "            query, batch_size\n",
    "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
    "        key = self.separate_heads(\n",
    "            key, batch_size\n",
    "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
    "        value = self.separate_heads(\n",
    "            value, batch_size\n",
    "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
    "        attention, weights = self.attention(query, key, value)\n",
    "        attention = tf.transpose(\n",
    "            attention, perm=[0, 2, 1, 3]\n",
    "        )  # (batch_size, seq_len, num_heads, projection_dim)\n",
    "        concat_attention = tf.reshape(\n",
    "            attention, (batch_size, -1, self.embed_dim)\n",
    "        )  # (batch_size, seq_len, embed_dim)\n",
    "        output = self.combine_heads(\n",
    "            concat_attention\n",
    "        )  # (batch_size, seq_len, embed_dim)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformer Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenAndPositionEmbedding(layers.Layer):\n",
    "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
    "        super(TokenAndPositionEmbedding, self).__init__()\n",
    "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
    "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[-1]\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        x = self.token_emb(x)\n",
    "        return x + positions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 32  # Embedding size for each token\n",
    "num_heads = 2  # Number of attention heads\n",
    "ff_dim = 32  # Hidden layer size in feed forward network inside transformer\n",
    "\n",
    "inputs = layers.Input(shape=(20,))\n",
    "embedding_layer = TokenAndPositionEmbedding(20, 1001, embed_dim)\n",
    "x = embedding_layer(inputs)\n",
    "transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
    "x = transformer_block(x)\n",
    "x = layers.GlobalAveragePooling1D()(x)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "x = layers.Dense(20, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "outputs = layers.Dense(5, activation=\"softmax\")(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1404/1404 [==============================] - 5s 3ms/step - loss: 0.9122 - accuracy: 0.5964 - val_loss: 0.9694 - val_accuracy: 0.5734\n",
      "Epoch 2/20\n",
      "1404/1404 [==============================] - 4s 3ms/step - loss: 0.9021 - accuracy: 0.6018 - val_loss: 0.9693 - val_accuracy: 0.5792\n",
      "Epoch 3/20\n",
      "1404/1404 [==============================] - 4s 3ms/step - loss: 0.8952 - accuracy: 0.6056 - val_loss: 0.9711 - val_accuracy: 0.5752\n",
      "Epoch 4/20\n",
      "1404/1404 [==============================] - 4s 3ms/step - loss: 0.8869 - accuracy: 0.6088 - val_loss: 0.9876 - val_accuracy: 0.5799\n",
      "Epoch 5/20\n",
      "1404/1404 [==============================] - 4s 3ms/step - loss: 0.8794 - accuracy: 0.6104 - val_loss: 0.9933 - val_accuracy: 0.5765\n",
      "Epoch 6/20\n",
      "1404/1404 [==============================] - 4s 3ms/step - loss: 0.8725 - accuracy: 0.6143 - val_loss: 0.9985 - val_accuracy: 0.5736\n",
      "Epoch 7/20\n",
      "1404/1404 [==============================] - 4s 3ms/step - loss: 0.8612 - accuracy: 0.6206 - val_loss: 0.9950 - val_accuracy: 0.5770\n",
      "Epoch 8/20\n",
      "1404/1404 [==============================] - 4s 3ms/step - loss: 0.8556 - accuracy: 0.6207 - val_loss: 1.0105 - val_accuracy: 0.5752\n",
      "Epoch 9/20\n",
      "1404/1404 [==============================] - 4s 3ms/step - loss: 0.8469 - accuracy: 0.6261 - val_loss: 1.0293 - val_accuracy: 0.5743\n",
      "Epoch 10/20\n",
      "1404/1404 [==============================] - 4s 3ms/step - loss: 0.8391 - accuracy: 0.6283 - val_loss: 1.0421 - val_accuracy: 0.5693\n",
      "Epoch 11/20\n",
      "1404/1404 [==============================] - 4s 3ms/step - loss: 0.8349 - accuracy: 0.6306 - val_loss: 1.0725 - val_accuracy: 0.5715\n",
      "Epoch 12/20\n",
      "1404/1404 [==============================] - 4s 3ms/step - loss: 0.8253 - accuracy: 0.6350 - val_loss: 1.0672 - val_accuracy: 0.5633\n",
      "Epoch 13/20\n",
      "1404/1404 [==============================] - 4s 3ms/step - loss: 0.8180 - accuracy: 0.6379 - val_loss: 1.1037 - val_accuracy: 0.5641\n",
      "Epoch 14/20\n",
      "1404/1404 [==============================] - 4s 3ms/step - loss: 0.8111 - accuracy: 0.6391 - val_loss: 1.0841 - val_accuracy: 0.5669\n",
      "Epoch 15/20\n",
      "1404/1404 [==============================] - 4s 3ms/step - loss: 0.8057 - accuracy: 0.6443 - val_loss: 1.1121 - val_accuracy: 0.5624\n",
      "Epoch 16/20\n",
      "1404/1404 [==============================] - 4s 3ms/step - loss: 0.7985 - accuracy: 0.6469 - val_loss: 1.1143 - val_accuracy: 0.5658\n",
      "Epoch 17/20\n",
      "1404/1404 [==============================] - 4s 3ms/step - loss: 0.7916 - accuracy: 0.6493 - val_loss: 1.1157 - val_accuracy: 0.5670\n",
      "Epoch 18/20\n",
      "1404/1404 [==============================] - 4s 3ms/step - loss: 0.7859 - accuracy: 0.6513 - val_loss: 1.1097 - val_accuracy: 0.5668\n",
      "Epoch 19/20\n",
      "1404/1404 [==============================] - 4s 3ms/step - loss: 0.7794 - accuracy: 0.6525 - val_loss: 1.1507 - val_accuracy: 0.5605\n",
      "Epoch 20/20\n",
      "1404/1404 [==============================] - 4s 3ms/step - loss: 0.7715 - accuracy: 0.6576 - val_loss: 1.1445 - val_accuracy: 0.5614\n"
     ]
    }
   ],
   "source": [
    "model.compile(\"adam\", \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "history = model.fit(encoded_train_reviews, train_ratings, batch_size=32, epochs=20, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "439/439 [==============================] - 1s 2ms/step - loss: 1.1208 - accuracy: 0.5587\n"
     ]
    }
   ],
   "source": [
    "score, acc = model.evaluate(encoded_test_reviews, test_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
